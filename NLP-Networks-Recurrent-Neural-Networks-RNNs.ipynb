{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "KpXQsS8nP9e6"
      },
      "outputs": [],
      "source": [
        "# importing the necessary library for rnn\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, SimpleRNN, Dense\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "#In this step, we import the necessary libraries, including NumPy for numerical operations\n",
        "#and TensorFlow/Keras for building and training neural networks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzRjXh2UQmSE"
      },
      "source": [
        "**Step 2: Sample Text Data and Labels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "lWAsqydTQM0X"
      },
      "outputs": [],
      "source": [
        "texts = [\n",
        "    \"This is a positive review.\",\n",
        "    \"I love this product.\",\n",
        "    \"Negative experience, would not recommend.\",\n",
        "    \"Terrible customer service.\",\n",
        "]\n",
        "\n",
        "labels = [1, 1, 0, 0]  # 1 for positive, and  0 for negative\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Here, we define sample text data (texts) and their corresponding labels (labels).\n",
        "#This dataset is used for sentiment analysis, where positive reviews are labeled as 1,\n",
        "#and negative reviews are labeled as 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Luk91-OgQ3zU"
      },
      "source": [
        "**Step 3: Tokenization and Padding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "qaktqP1rQ5UA"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=1000, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=10, padding=\"post\", truncating=\"post\")\n",
        "\n",
        "\n",
        "\n",
        "#In this step, we preprocess the text data:\n",
        "#Tokenizer is used to convert text into sequences of integers and create a vocabulary with a maximum of 1000 words.\n",
        "#texts_to_sequences converts the text into sequences of integer tokens.\n",
        "#pad_sequences ensures that all sequences have the same length (in this case, 10)\n",
        "#by padding shorter sequences with zeros and truncating longer sequences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ms3qhNHBREQv"
      },
      "source": [
        "**Step 4: Define the RNN Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "o3HR8sELRGDE"
      },
      "outputs": [],
      "source": [
        "# creating model \n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(input_dim=1000, output_dim=16, input_length=10))\n",
        "model.add(SimpleRNN(32))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "\n",
        "\n",
        "#Here, we define the RNN model using Keras:\n",
        "#An Embedding layer is used for word embeddings. It converts integer sequences into dense vectors.\n",
        "#A SimpleRNN layer with 32 units is added. This layer captures sequential patterns in the data.\n",
        "#A Dense layer with one output unit and a sigmoid activation function is added for binary sentiment classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEu9aVjsRSTD"
      },
      "source": [
        "**Step 5: Compiling the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "usQbAvHJRTk4"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "# compiling the model by specifying the optimizer (Adam),\n",
        "#loss function (binary cross-entropy), and evaluation metric (accuracy) for training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4IJjyS4Ra7v"
      },
      "source": [
        "**Step 6: Train the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "AQ9Y_egWRcfO"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(input_dim=100100, output_dim=16, input_length=14))\n",
        "model.add(SimpleRNN(32))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "\n",
        "#This step trains the model using the preprocessed data (padded_sequences) and labels.\n",
        "#The model is trained for 10 epochs, adjusting its internal parameters to minimize the loss function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bynmg7KRmpc"
      },
      "source": [
        "**Step 7: Make Predictions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Gm5mmNmRoTk",
        "outputId": "a2895da4-282b-473e-d3c1-239d630c28f7"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_28\" is incompatible with the layer: expected shape=(None, 14), found shape=(None, 12)\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[102], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m test_sequences \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mtexts_to_sequences(test_texts)\n\u001b[0;32m      3\u001b[0m padded_test_sequences \u001b[38;5;241m=\u001b[39m pad_sequences(test_sequences, maxlen\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncating\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadded_test_sequences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, text \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(test_texts):\n\u001b[0;32m      7\u001b[0m     sentiment \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m predictions[i] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileima_2fee.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_28\" is incompatible with the layer: expected shape=(None, 14), found shape=(None, 12)\n"
          ]
        }
      ],
      "source": [
        "test_texts = [\"Great service!\", \"Awful experience.\"]\n",
        "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
        "padded_test_sequences = pad_sequences(test_sequences, maxlen=12, padding=\"post\", truncating=\"post\")\n",
        "predictions = model.predict(padded_test_sequences)\n",
        "\n",
        "for i, text in enumerate(test_texts):\n",
        "    sentiment = \"positive\" if predictions[i] > 0.5 else \"negative\"\n",
        "    print(f\"Text: {text} | Predicted sentiment: {sentiment}\")\n",
        "\n",
        "\n",
        "\n",
        "#Finally, we use the trained model to make predictions on new test data (test_texts).\n",
        "#The code tokenizes and pads the test data similarly to the training data, and then\n",
        "#the model predicts the sentiment of each text. Predictions are printed, and \"positive\" or \"negative\"\n",
        "#labels are assigned based on the model's output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
